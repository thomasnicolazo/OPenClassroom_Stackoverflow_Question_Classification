{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219075b9-e6a0-4397-96cd-5c30f881a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import os\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "#scikitlearn & others\n",
    "\n",
    "import tokenization\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn.metrics as met\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cfb27e4-6c32-4dec-9b44-6d8755c0506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4881a9b9-dc5e-4305-b019-1c5a74ea6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 768755850098580163\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10087301120\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7888724104429196045\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e944935a-48ab-4d6e-936c-cc6db6aa4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# verify GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e86585-2752-4e02-9081-979c64bd79bf",
   "metadata": {},
   "source": [
    "# SETUP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fcc0615-97e4-43cc-a7a2-4265c22a0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/projet5/'\n",
    "path_res = path +'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f3f730-437d-4258-b514-56a3b3090c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'cleanDataprepSmote3.pickle','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67eae926-cf9c-4d86-a0cb-da46ec9515f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51904, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ec8fb4-ca59-47db-9872-dea200866eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                        object\n",
       "Body                         object\n",
       "Tags                         object\n",
       "text                         object\n",
       "nb_char                       int64\n",
       "tokens                       object\n",
       "tokens_title                 object\n",
       "nb_tokens                     int64\n",
       "tokens_unique                object\n",
       "nb_tokens_unique              int64\n",
       "tokens_WSW                   object\n",
       "tokens_title_WSW             object\n",
       "nb_tokens_WSW                 int64\n",
       "tokens_lemma                 object\n",
       "len_tokens_lemma              int64\n",
       "Tags_list                    object\n",
       "len _Tags_list                int64\n",
       "filtered_tags                object\n",
       "filtered_tags_reduced        object\n",
       "len_filtered_tags_reduced     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2714067e-dbfd-4dd8-a710-ebb10be83f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "      <th>nb_char</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_title</th>\n",
       "      <th>nb_tokens</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>nb_tokens_unique</th>\n",
       "      <th>tokens_WSW</th>\n",
       "      <th>tokens_title_WSW</th>\n",
       "      <th>nb_tokens_WSW</th>\n",
       "      <th>tokens_lemma</th>\n",
       "      <th>len_tokens_lemma</th>\n",
       "      <th>Tags_list</th>\n",
       "      <th>len _Tags_list</th>\n",
       "      <th>filtered_tags</th>\n",
       "      <th>filtered_tags_reduced</th>\n",
       "      <th>len_filtered_tags_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transpose/unzip function (inverse of zip)?</td>\n",
       "      <td>&lt;p&gt;I have a list of 2-item tuples and I'd like...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;matrix&gt;&lt;transpose&gt;</td>\n",
       "      <td>i have a list of 2-item tuples and i'd like to...</td>\n",
       "      <td>350</td>\n",
       "      <td>[i, have, a, list, of, 2, item, tuples, and, i...</td>\n",
       "      <td>[transpose, unzip, function, inverse, of, zip]</td>\n",
       "      <td>70</td>\n",
       "      <td>(c, example, 4, to, 1, become, tuple, 2, first...</td>\n",
       "      <td>42</td>\n",
       "      <td>[list, item, tuples, like, convert, lists, fir...</td>\n",
       "      <td>[transpose, unzip, function, inverse, zip]</td>\n",
       "      <td>28</td>\n",
       "      <td>[list, item, tuple, like, convert, list, first...</td>\n",
       "      <td>28</td>\n",
       "      <td>[list, matrix, transpose, python]</td>\n",
       "      <td>4</td>\n",
       "      <td>[list, python]</td>\n",
       "      <td>tag0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detecting audio silence in wav files using c#</td>\n",
       "      <td>&lt;p&gt;I'm tasked with building a .NET client app ...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;audio&gt;</td>\n",
       "      <td>i'm tasked with building a .net client app to ...</td>\n",
       "      <td>190</td>\n",
       "      <td>[i, m, tasked, with, building, a, net, client,...</td>\n",
       "      <td>[detecting, audio, silence, in, wav, files, us...</td>\n",
       "      <td>36</td>\n",
       "      <td>(app, apis, to, silence, libraries, m, a, wav,...</td>\n",
       "      <td>30</td>\n",
       "      <td>[tasked, building, net, client, app, detect, s...</td>\n",
       "      <td>[detecting, audio, silence, wav, files, using,...</td>\n",
       "      <td>17</td>\n",
       "      <td>[task, build, net, client, app, detect, silenc...</td>\n",
       "      <td>17</td>\n",
       "      <td>[.net, audio, c#]</td>\n",
       "      <td>3</td>\n",
       "      <td>[.net, c#]</td>\n",
       "      <td>tag1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to request a random row in sql?</td>\n",
       "      <td>&lt;p&gt;How can I request a random row (or as close...</td>\n",
       "      <td>&lt;sql&gt;&lt;random&gt;</td>\n",
       "      <td>how can i request a random row (or as close to...</td>\n",
       "      <td>89</td>\n",
       "      <td>[how, can, i, request, a, random, row, or, as,...</td>\n",
       "      <td>[how, to, request, a, random, row, in, sql]</td>\n",
       "      <td>19</td>\n",
       "      <td>(possible, or, a, request, row, to, how, truly...</td>\n",
       "      <td>17</td>\n",
       "      <td>[request, random, row, close, truly, random, p...</td>\n",
       "      <td>[request, random, row, sql]</td>\n",
       "      <td>9</td>\n",
       "      <td>[request, random, row, close, truly, random, p...</td>\n",
       "      <td>9</td>\n",
       "      <td>[random, sql]</td>\n",
       "      <td>2</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>tag108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detecting current iphone input language</td>\n",
       "      <td>&lt;p&gt;Does anybody knows, can I get the current i...</td>\n",
       "      <td>&lt;iphone&gt;&lt;keyboard&gt;</td>\n",
       "      <td>does anybody knows, can i get the current inpu...</td>\n",
       "      <td>166</td>\n",
       "      <td>[does, anybody, knows, can, i, get, the, curre...</td>\n",
       "      <td>[detecting, current, iphone, input, language]</td>\n",
       "      <td>28</td>\n",
       "      <td>(knows, notification, also, layout, a, when, a...</td>\n",
       "      <td>23</td>\n",
       "      <td>[anybody, knows, get, current, input, language...</td>\n",
       "      <td>[detecting, current, iphone, input, language]</td>\n",
       "      <td>16</td>\n",
       "      <td>[anybody, know, get, current, input, language,...</td>\n",
       "      <td>16</td>\n",
       "      <td>[iphone, keyboard]</td>\n",
       "      <td>2</td>\n",
       "      <td>[iphone]</td>\n",
       "      <td>tag11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how can i use homebrew to install both python ...</td>\n",
       "      <td>&lt;p&gt;I need to be able to switch back and forth ...</td>\n",
       "      <td>&lt;python&gt;&lt;homebrew&gt;</td>\n",
       "      <td>i need to be able to switch back and forth bet...</td>\n",
       "      <td>204</td>\n",
       "      <td>[i, need, to, be, able, to, switch, back, and,...</td>\n",
       "      <td>[how, can, i, use, homebrew, to, install, both...</td>\n",
       "      <td>44</td>\n",
       "      <td>(between, to, forth, using, 2, need, trouble, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>[need, able, switch, back, forth, python, usin...</td>\n",
       "      <td>[use, homebrew, install, python, mac]</td>\n",
       "      <td>16</td>\n",
       "      <td>[need, able, switch, back, forth, python, use,...</td>\n",
       "      <td>16</td>\n",
       "      <td>[homebrew, python]</td>\n",
       "      <td>2</td>\n",
       "      <td>[python]</td>\n",
       "      <td>tag0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0         transpose/unzip function (inverse of zip)?   \n",
       "1      detecting audio silence in wav files using c#   \n",
       "2                how to request a random row in sql?   \n",
       "4            detecting current iphone input language   \n",
       "6  how can i use homebrew to install both python ...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I have a list of 2-item tuples and I'd like...   \n",
       "1  <p>I'm tasked with building a .NET client app ...   \n",
       "2  <p>How can I request a random row (or as close...   \n",
       "4  <p>Does anybody knows, can I get the current i...   \n",
       "6  <p>I need to be able to switch back and forth ...   \n",
       "\n",
       "                                Tags  \\\n",
       "0  <python><list><matrix><transpose>   \n",
       "1                  <c#><.net><audio>   \n",
       "2                      <sql><random>   \n",
       "4                 <iphone><keyboard>   \n",
       "6                 <python><homebrew>   \n",
       "\n",
       "                                                text  nb_char  \\\n",
       "0  i have a list of 2-item tuples and i'd like to...      350   \n",
       "1  i'm tasked with building a .net client app to ...      190   \n",
       "2  how can i request a random row (or as close to...       89   \n",
       "4  does anybody knows, can i get the current inpu...      166   \n",
       "6  i need to be able to switch back and forth bet...      204   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, have, a, list, of, 2, item, tuples, and, i...   \n",
       "1  [i, m, tasked, with, building, a, net, client,...   \n",
       "2  [how, can, i, request, a, random, row, or, as,...   \n",
       "4  [does, anybody, knows, can, i, get, the, curre...   \n",
       "6  [i, need, to, be, able, to, switch, back, and,...   \n",
       "\n",
       "                                        tokens_title  nb_tokens  \\\n",
       "0     [transpose, unzip, function, inverse, of, zip]         70   \n",
       "1  [detecting, audio, silence, in, wav, files, us...         36   \n",
       "2        [how, to, request, a, random, row, in, sql]         19   \n",
       "4      [detecting, current, iphone, input, language]         28   \n",
       "6  [how, can, i, use, homebrew, to, install, both...         44   \n",
       "\n",
       "                                       tokens_unique  nb_tokens_unique  \\\n",
       "0  (c, example, 4, to, 1, become, tuple, 2, first...                42   \n",
       "1  (app, apis, to, silence, libraries, m, a, wav,...                30   \n",
       "2  (possible, or, a, request, row, to, how, truly...                17   \n",
       "4  (knows, notification, also, layout, a, when, a...                23   \n",
       "6  (between, to, forth, using, 2, need, trouble, ...                34   \n",
       "\n",
       "                                          tokens_WSW  \\\n",
       "0  [list, item, tuples, like, convert, lists, fir...   \n",
       "1  [tasked, building, net, client, app, detect, s...   \n",
       "2  [request, random, row, close, truly, random, p...   \n",
       "4  [anybody, knows, get, current, input, language...   \n",
       "6  [need, able, switch, back, forth, python, usin...   \n",
       "\n",
       "                                    tokens_title_WSW  nb_tokens_WSW  \\\n",
       "0         [transpose, unzip, function, inverse, zip]             28   \n",
       "1  [detecting, audio, silence, wav, files, using,...             17   \n",
       "2                        [request, random, row, sql]              9   \n",
       "4      [detecting, current, iphone, input, language]             16   \n",
       "6              [use, homebrew, install, python, mac]             16   \n",
       "\n",
       "                                        tokens_lemma  len_tokens_lemma  \\\n",
       "0  [list, item, tuple, like, convert, list, first...                28   \n",
       "1  [task, build, net, client, app, detect, silenc...                17   \n",
       "2  [request, random, row, close, truly, random, p...                 9   \n",
       "4  [anybody, know, get, current, input, language,...                16   \n",
       "6  [need, able, switch, back, forth, python, use,...                16   \n",
       "\n",
       "                           Tags_list  len _Tags_list   filtered_tags  \\\n",
       "0  [list, matrix, transpose, python]               4  [list, python]   \n",
       "1                  [.net, audio, c#]               3      [.net, c#]   \n",
       "2                      [random, sql]               2           [sql]   \n",
       "4                 [iphone, keyboard]               2        [iphone]   \n",
       "6                 [homebrew, python]               2        [python]   \n",
       "\n",
       "  filtered_tags_reduced  len_filtered_tags_reduced  \n",
       "0                  tag0                          1  \n",
       "1                  tag1                          1  \n",
       "2                tag108                          1  \n",
       "4                 tag11                          1  \n",
       "6                  tag0                          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbbef7-6796-413d-a712-b1397cf84526",
   "metadata": {},
   "source": [
    "## shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca8ec4c-d08b-406f-9c37-081e26d28180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequency(data):\n",
    "    ''' take pandas series and count words retun the occurences of the elements'''\n",
    "    freqTotal = {}\n",
    "    for text in data:\n",
    "        freq = nltk.Counter(text)\n",
    "        for word, count in freq.items():\n",
    "            if word in freqTotal.keys():\n",
    "                freqTotal[word] += count\n",
    "            else:\n",
    "                freqTotal[word] = count\n",
    "    return freqTotal\n",
    "\n",
    "def splitData(df,XCol,Ycol,ratioToKeep=1):\n",
    "    \"\"\" split data into two sets X and Y and then split them into  trainning and validation sets \n",
    "    the total will be 4 sets. the function returns pandas series or pandas dataframe types\"\"\"# add sample \n",
    "    df = df.sample(frac=ratioToKeep)\n",
    "    print(f'data used shape: {df.shape}')\n",
    "    X=df.loc[:,XCol]\n",
    "    y=df.loc[:,Ycol]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    print(f'X_train types:\\t{type(X_train)}')\n",
    "    print(f'X_test types:\\t{type(X_test)}')\n",
    "    print(f'Y_test types:\\t{type(y_test)}')\n",
    "    print(f'Y_train types:\\t{type(y_train)}')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def reduceData (Xtrain, Ytrain, ratioToKeep=0.2):\n",
    "    size = Xtrain.shape[0]\n",
    "    nbRowsToKeep = int(np.rint(size*ratioToKeep))\n",
    "    indRowToKeep = np.random.choice(size, nbRowsToKeep)\n",
    "    Xtrain = Xtrain[indRowToKeep,:]\n",
    "    Ytrain = Ytrain[indRowToKeep,:]\n",
    "    return (Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1527699-4c38-4f48-978d-f3dea152da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW(Xtrain, Xval):\n",
    "    \"\"\" set the BOW method for X train and validation sets.\"\"\"\n",
    "    Xtrain = Xtrain.apply(lambda x : ' '.join(x))\n",
    "    Xval = Xval.apply(lambda x : ' '.join(x))\n",
    "    XtrainCorpus = [x for x in Xtrain]\n",
    "    XvalCorpus = [x for x in Xval]\n",
    "    vectorizer = CountVectorizer()\n",
    "    Xtrain = vectorizer.fit_transform(XtrainCorpus)\n",
    "    print('-'*15)\n",
    "    print(f\"Xtrain vectorized shape: {Xtrain.shape}\\n\")\n",
    "    Xval = vectorizer.transform(XvalCorpus)\n",
    "    print(f\"Xval vectorized shape: {Xval.shape}\\n\")\n",
    "    return (Xtrain,Xval)\n",
    "\n",
    "def Binarize(Ytrain,Yval):\n",
    "    \"\"\"  binarize The tags for Y train and validation sets. \"\"\"\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([Ytrain]) # if Y is not list of list, mlb.fit(['sci-fi', 'thriller', 'comedy']) -> array(['-', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'o', 'r', 's', 't','y'], dtype=object)\n",
    "    for i in Ytrain.index:\n",
    "        Ytrain.loc[i] = mlb.transform([[Ytrain.loc[i]]])[0]\n",
    "    for i in Yval.index:\n",
    "        Yval.loc[i] = mlb.transform([[Yval.loc[i]]])[0]\n",
    "    labels = mlb.classes_\n",
    "    print('-'*15)\n",
    "    print(f\"Ytrain vectorized shape: {Ytrain.shape}\\n\")\n",
    "    print(f\"Yval vectorized shape: {Yval.shape}\\n\")\n",
    "    print(f\"classes : {mlb.classes_}\")\n",
    "    return (Ytrain,Yval, labels)\n",
    "\n",
    "def plotRoc():\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(labels)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_val[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr[2],\n",
    "        tpr[2],\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clfScore(model,Xval, Yval, labels, fileName,PATH=path_res):                           #  correct position of the labels ???\n",
    "    y_pred = model.predict(Xval)\n",
    "    F1score=met.f1_score(y_pred, Yval, average=None)\n",
    "    preciScore=met.precision_score(y_pred, Yval, average=None)\n",
    "    recallScore=met.recall_score(y_pred, Yval, average=None)\n",
    "    print(f'{\"Tags\":25}\\t\\t F-score\\t\\t precision\\t\\t recall\\n')\n",
    "    with open(PATH + fileName,'w') as f:\n",
    "        for ind,name in enumerate(labels):\n",
    "            f.write(f'{name:25}\\t\\t {F1score[ind]:4f}\\t\\t {preciScore[ind]:4f}\\t\\t {recallScore[ind]:4f}\\n')\n",
    "            print(f'{name:25}\\t\\t {F1score[ind]:4f}\\t\\t {preciScore[ind]:4f}\\t\\t {recallScore[ind]:4f}')\n",
    "    #plotRoc(labels,y_pred,y_val)\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77b929-0cf7-406b-bda2-c7f8243b6552",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10e631e-143f-4d61-9608-625411ec13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f80438b2-2632-4214-8963-0df0e559f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "encoderModel = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f6fddc-d955-4097-9b7c-28cd4e8b2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    time1 = time.time()\n",
    "    divisor = len(sentences)//batch_size\n",
    "    remainder = len(sentences)%batch_size\n",
    "    for step in range(divisor) :\n",
    "        idx = step*batch_size\n",
    "        feat = encoderModel(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "        if (step+1) == divisor and remainder !=0:\n",
    "            feat = encoderModel(sentences[divisor*batch_size:])\n",
    "            features = np.concatenate((features,feat))\n",
    "\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8e476ba-6773-4b81-9cae-c96a50a33947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data used shape: (25952, 20)\n",
      "X_train types:\t<class 'pandas.core.series.Series'>\n",
      "X_test types:\t<class 'pandas.core.series.Series'>\n",
      "Y_test types:\t<class 'pandas.core.series.Series'>\n",
      "Y_train types:\t<class 'pandas.core.series.Series'>\n",
      "y_train shape: (17387,)\n",
      "\n",
      "y_val shape: (8565,)\n",
      "\n",
      "X_train shape: (17387,)\n",
      "\n",
      "X_val shape: (8565,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = splitData(data,XCol='tokens_WSW',Ycol='filtered_tags_reduced',ratioToKeep=0.5) # too much time without sampling\n",
    "print(f\"y_train shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val shape: {y_val.shape}\\n\")\n",
    "print(f\"X_train shape: {X_train.shape}\\n\")\n",
    "print(f\"X_val shape: {X_val.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a738c9-d6d9-4dfb-a1aa-de1a0c1105e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: ' '.join(x).strip())\n",
    "X_val = X_val.apply(lambda x: ' '.join(x).strip())\n",
    "X_val.reset_index(inplace=True,drop=True)\n",
    "X_train.reset_index(inplace=True,drop=True)\n",
    "y_train.reset_index(inplace=True,drop=True)\n",
    "y_val.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f40f9a6-85cc-4e74-a3a8-4eaaf2ee1e3a",
   "metadata": {},
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load pre-trained universal sentence encoder model\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Sentences for which you want to create embeddings,\n",
    "# passed as an array in embed()\n",
    "Sentences = [\n",
    "    \"How old are you\",\n",
    "    \"What is your age\",\n",
    "    \"I love to watch Television\",\n",
    "    \"I am wearing a wrist watch\"\n",
    "]\n",
    "embeddings = embed(Sentences)\n",
    "\n",
    "# Printing embeddings of each sentence\n",
    "print(embeddings)\n",
    "\n",
    "# To print each embeddings along with its corresponding\n",
    "# sentence below code can be used.\n",
    "for i in range(len(Sentences)):\n",
    "    print(Sentences[i])\n",
    "    print(embeddings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1f1e29-2816-4596-8424-ea18e82de722",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "X_train = X_train.to_list()\n",
    "X_val = X_val.to_list()\n",
    "X_train = feature_USE_fct(X_train, batch_size)\n",
    "X_val = feature_USE_fct(X_val, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840a30d3-d5ee-402d-a9d2-e685cd714447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Ytrain vectorized shape: (17387,)\n",
      "\n",
      "Yval vectorized shape: (8565,)\n",
      "\n",
      "classes : ['tag0' 'tag1' 'tag10' 'tag108' 'tag11' 'tag12' 'tag13' 'tag14' 'tag15'\n",
      " 'tag16' 'tag17' 'tag18' 'tag19' 'tag2' 'tag20' 'tag21' 'tag22' 'tag23'\n",
      " 'tag24' 'tag25' 'tag26' 'tag27' 'tag28' 'tag29' 'tag3' 'tag30' 'tag31'\n",
      " 'tag32' 'tag33' 'tag34' 'tag35' 'tag36' 'tag37' 'tag38' 'tag4' 'tag5'\n",
      " 'tag6' 'tag7' 'tag8' 'tag9']\n",
      "y_train vectorized shape: (17387, 40)\n",
      "\n",
      "y_val vectorized shape: (8565, 40)\n",
      "\n",
      "---- After SMOTE ----\n",
      "y_train vectorized shape: (71240, 40)\n",
      "\n",
      "X_train vectorized shape: (71240, 512)\n",
      "\n",
      "---- Reduce size training set ----\n",
      "y_train vectorized shape: (35620, 40)\n",
      "\n",
      "y_val vectorized shape: (8565, 40)\n",
      "\n",
      "X_train vectorized shape: (35620, 512)\n",
      "\n",
      "X_val vectorized shape: (8565, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_train = ['nice','bad','nice']\n",
    "#y_val = ['nice','bad']\n",
    "\n",
    "y_train, y_val, labels = Binarize(y_train,y_val)\n",
    "y_train = [ i for i in y_train]\n",
    "y_val = [ i for i in y_val]\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val vectorized shape: {y_val.shape}\\n\")\n",
    "\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train) # SMOTE\n",
    "X_train, y_train = shuffle(X_train,y_train, random_state=1)\n",
    "print(f\"---- After SMOTE ----\")\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"X_train vectorized shape: {X_train.shape}\\n\")\n",
    "\n",
    "print(f\"---- Reduce size training set ----\")\n",
    "X_train, y_train = reduceData(X_train ,y_train,ratioToKeep=0.5) #0.05\n",
    "\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val vectorized shape: {y_val.shape}\\n\")\n",
    "print(f\"X_train vectorized shape: {X_train.shape}\\n\")\n",
    "print(f\"X_val vectorized shape: {X_val.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd32f7e-17a0-48e1-92d9-bd64e8e80c53",
   "metadata": {},
   "source": [
    "###  logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c59db9-5b8c-4548-b54b-22974fa32c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "{'estimator__estimator__C': 5}\n"
     ]
    }
   ],
   "source": [
    "#y_train, y_val, labels = Binarize(y_train,y_val)\n",
    "\n",
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0))\n",
    "\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler()),('estimator',log_clf)])\n",
    "#raise Exception(\"trop long\") \n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__estimator__C': [0.1, 0.5, 1., 5, 10]}] # lambda regularization\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(model,\n",
    "                   param_grid,\n",
    "                   scoring='f1_macro', #F1 = 2 * (precision * recall) / (precision + recall)\n",
    "                   n_jobs=-1,\n",
    "                   verbose=0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "log_clf_best_param = clf.best_params_['estimator__estimator__C']\n",
    "print('Meilleurs hyper-paramètres :')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa85aed-cb48-45f5-832f-f39c25f896b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags                     \t\t F-score\t\t precision\t\t recall\n",
      "\n",
      "tag0                     \t\t 0.564356\t\t 0.457045\t\t 0.737523\n",
      "tag1                     \t\t 0.364677\t\t 0.257803\t\t 0.622905\n",
      "tag10                    \t\t 0.374728\t\t 0.436548\t\t 0.328244\n",
      "tag108                   \t\t 0.453721\t\t 0.498008\t\t 0.416667\n",
      "tag11                    \t\t 0.291829\t\t 0.365854\t\t 0.242718\n",
      "tag12                    \t\t 0.808140\t\t 0.817647\t\t 0.798851\n",
      "tag13                    \t\t 0.252588\t\t 0.321053\t\t 0.208191\n",
      "tag14                    \t\t 0.340314\t\t 0.445205\t\t 0.275424\n",
      "tag15                    \t\t 0.262626\t\t 0.376812\t\t 0.201550\n",
      "tag16                    \t\t 0.203310\t\t 0.328244\t\t 0.147260\n",
      "tag17                    \t\t 0.204489\t\t 0.305970\t\t 0.153558\n",
      "tag18                    \t\t 0.176471\t\t 0.294643\t\t 0.125954\n",
      "tag19                    \t\t 0.310231\t\t 0.419643\t\t 0.246073\n",
      "tag2                     \t\t 0.523810\t\t 0.447025\t\t 0.632444\n",
      "tag20                    \t\t 0.213873\t\t 0.308333\t\t 0.163717\n",
      "tag21                    \t\t 0.279070\t\t 0.342857\t\t 0.235294\n",
      "tag22                    \t\t 0.215873\t\t 0.317757\t\t 0.163462\n",
      "tag23                    \t\t 0.374046\t\t 0.485149\t\t 0.304348\n",
      "tag24                    \t\t 0.100890\t\t 0.180851\t\t 0.069959\n",
      "tag25                    \t\t 0.377358\t\t 0.490196\t\t 0.306748\n",
      "tag26                    \t\t 0.236559\t\t 0.370787\t\t 0.173684\n",
      "tag27                    \t\t 0.174194\t\t 0.236842\t\t 0.137755\n",
      "tag28                    \t\t 0.532663\t\t 0.638554\t\t 0.456897\n",
      "tag29                    \t\t 0.282353\t\t 0.461538\t\t 0.203390\n",
      "tag3                     \t\t 0.423469\t\t 0.322957\t\t 0.614815\n",
      "tag30                    \t\t 0.425743\t\t 0.565789\t\t 0.341270\n",
      "tag31                    \t\t 0.448485\t\t 0.521127\t\t 0.393617\n",
      "tag32                    \t\t 0.218182\t\t 0.333333\t\t 0.162162\n",
      "tag33                    \t\t 0.333333\t\t 0.458333\t\t 0.261905\n",
      "tag34                    \t\t 0.147783\t\t 0.200000\t\t 0.117188\n",
      "tag35                    \t\t 0.423077\t\t 0.532258\t\t 0.351064\n",
      "tag36                    \t\t 0.074074\t\t 0.109589\t\t 0.055944\n",
      "tag37                    \t\t 0.409938\t\t 0.464789\t\t 0.366667\n",
      "tag38                    \t\t 0.358974\t\t 0.424242\t\t 0.311111\n",
      "tag4                     \t\t 0.494024\t\t 0.460396\t\t 0.532951\n",
      "tag5                     \t\t 0.714459\t\t 0.735000\t\t 0.695035\n",
      "tag6                     \t\t 0.458746\t\t 0.476027\t\t 0.442675\n",
      "tag7                     \t\t 0.246154\t\t 0.271186\t\t 0.225352\n",
      "tag8                     \t\t 0.387097\t\t 0.383333\t\t 0.390935\n",
      "tag9                     \t\t 0.323049\t\t 0.395556\t\t 0.273006\n"
     ]
    }
   ],
   "source": [
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=42,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0,\n",
    "                                                C=log_clf_best_param))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler()),('estimator',log_clf)])\n",
    "model.fit(X_train, y_train)\n",
    "clfScore(model, X_val,y_val, labels,'USE_logistic_reduced_without_empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491223a9-0dec-456a-818d-8d700bad19e1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f9e874-009b-4bbb-ab2b-35e70693f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "{'estimator__estimator__max_depth': 15, 'estimator__estimator__n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "RF_clf = OneVsRestClassifier(RF(min_samples_split=5))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler(with_mean=False)),('estimator',RF_clf)])\n",
    "#raise Exception(\"trop long\") \n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__estimator__n_estimators': [10,20,30],'estimator__estimator__max_depth' : [5,8,10,15]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(model,\n",
    "                   param_grid,\n",
    "                   scoring='f1_macro', #F1 = 2 * (precision * recall) / (precision + recall)\n",
    "                   n_jobs=-1,\n",
    "                   verbose=0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "RF_clf_best_param1 = clf.best_params_['estimator__estimator__n_estimators']\n",
    "RF_clf_best_param2 = clf.best_params_['estimator__estimator__max_depth']\n",
    "print('Meilleurs hyper-paramètres :')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e3c4eb4-5289-4862-8462-4ca23e597896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags                     \t\t F-score\t\t precision\t\t recall\n",
      "\n",
      "tag0                     \t\t 0.223541\t\t 0.129439\t\t 0.818841\n",
      "tag1                     \t\t 0.031180\t\t 0.016185\t\t 0.424242\n",
      "tag10                    \t\t 0.335404\t\t 0.274112\t\t 0.432000\n",
      "tag108                   \t\t 0.360563\t\t 0.254980\t\t 0.615385\n",
      "tag11                    \t\t 0.073801\t\t 0.048780\t\t 0.151515\n",
      "tag12                    \t\t 0.724739\t\t 0.611765\t\t 0.888889\n",
      "tag13                    \t\t 0.041152\t\t 0.026316\t\t 0.094340\n",
      "tag14                    \t\t 0.259615\t\t 0.184932\t\t 0.435484\n",
      "tag15                    \t\t 0.048193\t\t 0.028986\t\t 0.142857\n",
      "tag16                    \t\t 0.148571\t\t 0.099237\t\t 0.295455\n",
      "tag17                    \t\t 0.105263\t\t 0.067164\t\t 0.243243\n",
      "tag18                    \t\t 0.083832\t\t 0.062500\t\t 0.127273\n",
      "tag19                    \t\t 0.184397\t\t 0.116071\t\t 0.448276\n",
      "tag2                     \t\t 0.257143\t\t 0.156749\t\t 0.715232\n",
      "tag20                    \t\t 0.162500\t\t 0.108333\t\t 0.325000\n",
      "tag21                    \t\t 0.117647\t\t 0.076190\t\t 0.258065\n",
      "tag22                    \t\t 0.058824\t\t 0.037383\t\t 0.137931\n",
      "tag23                    \t\t 0.305732\t\t 0.237624\t\t 0.428571\n",
      "tag24                    \t\t 0.047244\t\t 0.031915\t\t 0.090909\n",
      "tag25                    \t\t 0.248366\t\t 0.186275\t\t 0.372549\n",
      "tag26                    \t\t 0.114286\t\t 0.089888\t\t 0.156863\n",
      "tag27                    \t\t 0.072993\t\t 0.043860\t\t 0.217391\n",
      "tag28                    \t\t 0.302521\t\t 0.216867\t\t 0.500000\n",
      "tag29                    \t\t 0.137931\t\t 0.115385\t\t 0.171429\n",
      "tag3                     \t\t 0.187845\t\t 0.110246\t\t 0.634328\n",
      "tag30                    \t\t 0.341085\t\t 0.289474\t\t 0.415094\n",
      "tag31                    \t\t 0.412214\t\t 0.380282\t\t 0.450000\n",
      "tag32                    \t\t 0.227273\t\t 0.208333\t\t 0.250000\n",
      "tag33                    \t\t 0.232143\t\t 0.180556\t\t 0.325000\n",
      "tag34                    \t\t 0.062500\t\t 0.040000\t\t 0.142857\n",
      "tag35                    \t\t 0.342857\t\t 0.290323\t\t 0.418605\n",
      "tag36                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag37                    \t\t 0.288462\t\t 0.211268\t\t 0.454545\n",
      "tag38                    \t\t 0.341085\t\t 0.333333\t\t 0.349206\n",
      "tag4                     \t\t 0.193416\t\t 0.116337\t\t 0.573171\n",
      "tag5                     \t\t 0.680473\t\t 0.575000\t\t 0.833333\n",
      "tag6                     \t\t 0.314214\t\t 0.215753\t\t 0.577982\n",
      "tag7                     \t\t 0.027933\t\t 0.016949\t\t 0.079365\n",
      "tag8                     \t\t 0.109005\t\t 0.063889\t\t 0.370968\n",
      "tag9                     \t\t 0.129964\t\t 0.080000\t\t 0.346154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DevPackages\\lib\\site-packages\\joblib\\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\\Users\\thomas\\AppData\\Local\\Temp\\joblib_memmapping_folder_2160_a0861911983344f7a3b23081f38cc110_c4c0d6b4136740e497931b5481e7b670\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "D:\\DevPackages\\lib\\site-packages\\joblib\\_memmapping_reducer.py:607: UserWarning: Failed to delete temporary folder: C:\\Users\\thomas\\AppData\\Local\\Temp\\joblib_memmapping_folder_2160_ece8b610232544889d2de0e3a92b8c14_f746d67d3f1a4876b62ece5d88f64c33\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n"
     ]
    }
   ],
   "source": [
    "RF_clf = OneVsRestClassifier(RF(n_estimators=RF_clf_best_param1,\n",
    "                                                  max_depth=RF_clf_best_param2,\n",
    "                                                   min_samples_split=5))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler(with_mean=False)),('estimator',RF_clf)])\n",
    "model.fit(X_train, y_train)\n",
    "clfScore(model, X_val,y_val, labels,'USE_RF_reduced_without_empty')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
