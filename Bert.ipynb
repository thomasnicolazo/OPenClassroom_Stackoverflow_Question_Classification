{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19432e37-6484-4d22-a706-a3f412a668ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import os\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "#scikitlearn & others\n",
    "\n",
    "import tokenization\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn.metrics as met\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c386f3a-d712-493c-a2ee-c251161e020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d45c13-5181-41c9-9946-6a7c3397e28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7054225820035173254\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10087301120\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2718956426686775445\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28137121-1d7a-49e0-9f2a-4948f41aa523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# verify GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4fa1ef8-ca93-423b-b95e-40e2a8b5bbca",
   "metadata": {},
   "source": [
    "# if multi GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dbc697c-d56c-4ee6-aa01-8ce251daa700",
   "metadata": {},
   "source": [
    "# if multi GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=2048)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cab9c9e0-e0d0-460e-b9fd-e1ef6c0dbb1e",
   "metadata": {},
   "source": [
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "#from silence_tensorflow import silence_tensorflow\n",
    "#silence_tensorflow()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b43103-08a0-4c9b-8a7b-185a9585391c",
   "metadata": {},
   "source": [
    "# SETUP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f01805-328e-4405-b8f0-7c2474057a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/projet5/'\n",
    "path_res = path +'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5431c441-e302-4280-8c50-6bd27005edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'cleanDataprepSmote3.pickle','rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0138d7d8-1848-4eae-bebd-a60eb15c06df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51904, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad85b92-38ca-4a49-a8ba-a58ccc7959fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                        object\n",
       "Body                         object\n",
       "Tags                         object\n",
       "text                         object\n",
       "nb_char                       int64\n",
       "tokens                       object\n",
       "tokens_title                 object\n",
       "nb_tokens                     int64\n",
       "tokens_unique                object\n",
       "nb_tokens_unique              int64\n",
       "tokens_WSW                   object\n",
       "tokens_title_WSW             object\n",
       "nb_tokens_WSW                 int64\n",
       "tokens_lemma                 object\n",
       "len_tokens_lemma              int64\n",
       "Tags_list                    object\n",
       "len _Tags_list                int64\n",
       "filtered_tags                object\n",
       "filtered_tags_reduced        object\n",
       "len_filtered_tags_reduced     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9adf4007-a522-4984-aa28-f70f14d44e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "      <th>nb_char</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_title</th>\n",
       "      <th>nb_tokens</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>nb_tokens_unique</th>\n",
       "      <th>tokens_WSW</th>\n",
       "      <th>tokens_title_WSW</th>\n",
       "      <th>nb_tokens_WSW</th>\n",
       "      <th>tokens_lemma</th>\n",
       "      <th>len_tokens_lemma</th>\n",
       "      <th>Tags_list</th>\n",
       "      <th>len _Tags_list</th>\n",
       "      <th>filtered_tags</th>\n",
       "      <th>filtered_tags_reduced</th>\n",
       "      <th>len_filtered_tags_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transpose/unzip function (inverse of zip)?</td>\n",
       "      <td>&lt;p&gt;I have a list of 2-item tuples and I'd like...</td>\n",
       "      <td>&lt;python&gt;&lt;list&gt;&lt;matrix&gt;&lt;transpose&gt;</td>\n",
       "      <td>i have a list of 2-item tuples and i'd like to...</td>\n",
       "      <td>350</td>\n",
       "      <td>[i, have, a, list, of, 2, item, tuples, and, i...</td>\n",
       "      <td>[transpose, unzip, function, inverse, of, zip]</td>\n",
       "      <td>70</td>\n",
       "      <td>(c, example, 4, to, 1, become, tuple, 2, first...</td>\n",
       "      <td>42</td>\n",
       "      <td>[list, item, tuples, like, convert, lists, fir...</td>\n",
       "      <td>[transpose, unzip, function, inverse, zip]</td>\n",
       "      <td>28</td>\n",
       "      <td>[list, item, tuple, like, convert, list, first...</td>\n",
       "      <td>28</td>\n",
       "      <td>[list, matrix, transpose, python]</td>\n",
       "      <td>4</td>\n",
       "      <td>[list, python]</td>\n",
       "      <td>tag0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detecting audio silence in wav files using c#</td>\n",
       "      <td>&lt;p&gt;I'm tasked with building a .NET client app ...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;audio&gt;</td>\n",
       "      <td>i'm tasked with building a .net client app to ...</td>\n",
       "      <td>190</td>\n",
       "      <td>[i, m, tasked, with, building, a, net, client,...</td>\n",
       "      <td>[detecting, audio, silence, in, wav, files, us...</td>\n",
       "      <td>36</td>\n",
       "      <td>(app, apis, to, silence, libraries, m, a, wav,...</td>\n",
       "      <td>30</td>\n",
       "      <td>[tasked, building, net, client, app, detect, s...</td>\n",
       "      <td>[detecting, audio, silence, wav, files, using,...</td>\n",
       "      <td>17</td>\n",
       "      <td>[task, build, net, client, app, detect, silenc...</td>\n",
       "      <td>17</td>\n",
       "      <td>[.net, audio, c#]</td>\n",
       "      <td>3</td>\n",
       "      <td>[.net, c#]</td>\n",
       "      <td>tag1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to request a random row in sql?</td>\n",
       "      <td>&lt;p&gt;How can I request a random row (or as close...</td>\n",
       "      <td>&lt;sql&gt;&lt;random&gt;</td>\n",
       "      <td>how can i request a random row (or as close to...</td>\n",
       "      <td>89</td>\n",
       "      <td>[how, can, i, request, a, random, row, or, as,...</td>\n",
       "      <td>[how, to, request, a, random, row, in, sql]</td>\n",
       "      <td>19</td>\n",
       "      <td>(possible, or, a, request, row, to, how, truly...</td>\n",
       "      <td>17</td>\n",
       "      <td>[request, random, row, close, truly, random, p...</td>\n",
       "      <td>[request, random, row, sql]</td>\n",
       "      <td>9</td>\n",
       "      <td>[request, random, row, close, truly, random, p...</td>\n",
       "      <td>9</td>\n",
       "      <td>[random, sql]</td>\n",
       "      <td>2</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>tag108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detecting current iphone input language</td>\n",
       "      <td>&lt;p&gt;Does anybody knows, can I get the current i...</td>\n",
       "      <td>&lt;iphone&gt;&lt;keyboard&gt;</td>\n",
       "      <td>does anybody knows, can i get the current inpu...</td>\n",
       "      <td>166</td>\n",
       "      <td>[does, anybody, knows, can, i, get, the, curre...</td>\n",
       "      <td>[detecting, current, iphone, input, language]</td>\n",
       "      <td>28</td>\n",
       "      <td>(knows, notification, also, layout, a, when, a...</td>\n",
       "      <td>23</td>\n",
       "      <td>[anybody, knows, get, current, input, language...</td>\n",
       "      <td>[detecting, current, iphone, input, language]</td>\n",
       "      <td>16</td>\n",
       "      <td>[anybody, know, get, current, input, language,...</td>\n",
       "      <td>16</td>\n",
       "      <td>[iphone, keyboard]</td>\n",
       "      <td>2</td>\n",
       "      <td>[iphone]</td>\n",
       "      <td>tag11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how can i use homebrew to install both python ...</td>\n",
       "      <td>&lt;p&gt;I need to be able to switch back and forth ...</td>\n",
       "      <td>&lt;python&gt;&lt;homebrew&gt;</td>\n",
       "      <td>i need to be able to switch back and forth bet...</td>\n",
       "      <td>204</td>\n",
       "      <td>[i, need, to, be, able, to, switch, back, and,...</td>\n",
       "      <td>[how, can, i, use, homebrew, to, install, both...</td>\n",
       "      <td>44</td>\n",
       "      <td>(between, to, forth, using, 2, need, trouble, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>[need, able, switch, back, forth, python, usin...</td>\n",
       "      <td>[use, homebrew, install, python, mac]</td>\n",
       "      <td>16</td>\n",
       "      <td>[need, able, switch, back, forth, python, use,...</td>\n",
       "      <td>16</td>\n",
       "      <td>[homebrew, python]</td>\n",
       "      <td>2</td>\n",
       "      <td>[python]</td>\n",
       "      <td>tag0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0         transpose/unzip function (inverse of zip)?   \n",
       "1      detecting audio silence in wav files using c#   \n",
       "2                how to request a random row in sql?   \n",
       "4            detecting current iphone input language   \n",
       "6  how can i use homebrew to install both python ...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I have a list of 2-item tuples and I'd like...   \n",
       "1  <p>I'm tasked with building a .NET client app ...   \n",
       "2  <p>How can I request a random row (or as close...   \n",
       "4  <p>Does anybody knows, can I get the current i...   \n",
       "6  <p>I need to be able to switch back and forth ...   \n",
       "\n",
       "                                Tags  \\\n",
       "0  <python><list><matrix><transpose>   \n",
       "1                  <c#><.net><audio>   \n",
       "2                      <sql><random>   \n",
       "4                 <iphone><keyboard>   \n",
       "6                 <python><homebrew>   \n",
       "\n",
       "                                                text  nb_char  \\\n",
       "0  i have a list of 2-item tuples and i'd like to...      350   \n",
       "1  i'm tasked with building a .net client app to ...      190   \n",
       "2  how can i request a random row (or as close to...       89   \n",
       "4  does anybody knows, can i get the current inpu...      166   \n",
       "6  i need to be able to switch back and forth bet...      204   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [i, have, a, list, of, 2, item, tuples, and, i...   \n",
       "1  [i, m, tasked, with, building, a, net, client,...   \n",
       "2  [how, can, i, request, a, random, row, or, as,...   \n",
       "4  [does, anybody, knows, can, i, get, the, curre...   \n",
       "6  [i, need, to, be, able, to, switch, back, and,...   \n",
       "\n",
       "                                        tokens_title  nb_tokens  \\\n",
       "0     [transpose, unzip, function, inverse, of, zip]         70   \n",
       "1  [detecting, audio, silence, in, wav, files, us...         36   \n",
       "2        [how, to, request, a, random, row, in, sql]         19   \n",
       "4      [detecting, current, iphone, input, language]         28   \n",
       "6  [how, can, i, use, homebrew, to, install, both...         44   \n",
       "\n",
       "                                       tokens_unique  nb_tokens_unique  \\\n",
       "0  (c, example, 4, to, 1, become, tuple, 2, first...                42   \n",
       "1  (app, apis, to, silence, libraries, m, a, wav,...                30   \n",
       "2  (possible, or, a, request, row, to, how, truly...                17   \n",
       "4  (knows, notification, also, layout, a, when, a...                23   \n",
       "6  (between, to, forth, using, 2, need, trouble, ...                34   \n",
       "\n",
       "                                          tokens_WSW  \\\n",
       "0  [list, item, tuples, like, convert, lists, fir...   \n",
       "1  [tasked, building, net, client, app, detect, s...   \n",
       "2  [request, random, row, close, truly, random, p...   \n",
       "4  [anybody, knows, get, current, input, language...   \n",
       "6  [need, able, switch, back, forth, python, usin...   \n",
       "\n",
       "                                    tokens_title_WSW  nb_tokens_WSW  \\\n",
       "0         [transpose, unzip, function, inverse, zip]             28   \n",
       "1  [detecting, audio, silence, wav, files, using,...             17   \n",
       "2                        [request, random, row, sql]              9   \n",
       "4      [detecting, current, iphone, input, language]             16   \n",
       "6              [use, homebrew, install, python, mac]             16   \n",
       "\n",
       "                                        tokens_lemma  len_tokens_lemma  \\\n",
       "0  [list, item, tuple, like, convert, list, first...                28   \n",
       "1  [task, build, net, client, app, detect, silenc...                17   \n",
       "2  [request, random, row, close, truly, random, p...                 9   \n",
       "4  [anybody, know, get, current, input, language,...                16   \n",
       "6  [need, able, switch, back, forth, python, use,...                16   \n",
       "\n",
       "                           Tags_list  len _Tags_list   filtered_tags  \\\n",
       "0  [list, matrix, transpose, python]               4  [list, python]   \n",
       "1                  [.net, audio, c#]               3      [.net, c#]   \n",
       "2                      [random, sql]               2           [sql]   \n",
       "4                 [iphone, keyboard]               2        [iphone]   \n",
       "6                 [homebrew, python]               2        [python]   \n",
       "\n",
       "  filtered_tags_reduced  len_filtered_tags_reduced  \n",
       "0                  tag0                          1  \n",
       "1                  tag1                          1  \n",
       "2                tag108                          1  \n",
       "4                 tag11                          1  \n",
       "6                  tag0                          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d9c85-d630-45b7-9aaf-17dab24ec378",
   "metadata": {},
   "source": [
    "## shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ea93a2-a8d9-4434-8425-36f581328a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordFrequency(data):\n",
    "    ''' take pandas series and count words retun the occurences of the elements'''\n",
    "    freqTotal = {}\n",
    "    for text in data:\n",
    "        freq = nltk.Counter(text)\n",
    "        for word, count in freq.items():\n",
    "            if word in freqTotal.keys():\n",
    "                freqTotal[word] += count\n",
    "            else:\n",
    "                freqTotal[word] = count\n",
    "    return freqTotal\n",
    "\n",
    "def splitData(df,XCol,Ycol,ratioToKeep=1):\n",
    "    \"\"\" split data into two sets X and Y and then split them into  trainning and validation sets \n",
    "    the total will be 4 sets. the function returns pandas series or pandas dataframe types\"\"\"# add sample \n",
    "    df = df.sample(frac=ratioToKeep)\n",
    "    print(f'data used shape: {df.shape}')\n",
    "    X=df.loc[:,XCol]\n",
    "    y=df.loc[:,Ycol]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    print(f'X_train types:\\t{type(X_train)}')\n",
    "    print(f'X_test types:\\t{type(X_test)}')\n",
    "    print(f'Y_test types:\\t{type(y_test)}')\n",
    "    print(f'Y_train types:\\t{type(y_train)}')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def reduceData (Xtrain, Ytrain, ratioToKeep=0.2):\n",
    "    size = Xtrain.shape[0]\n",
    "    nbRowsToKeep = int(np.rint(size*ratioToKeep))\n",
    "    indRowToKeep = np.random.choice(size, nbRowsToKeep)\n",
    "    Xtrain = Xtrain[indRowToKeep,:]\n",
    "    Ytrain = Ytrain[indRowToKeep,:]\n",
    "    return (Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c5b429-d649-41fc-ad5b-84f15dde9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BOW(Xtrain, Xval):\n",
    "    \"\"\" set the BOW method for X train and validation sets.\"\"\"\n",
    "    Xtrain = Xtrain.apply(lambda x : ' '.join(x))\n",
    "    Xval = Xval.apply(lambda x : ' '.join(x))\n",
    "    XtrainCorpus = [x for x in Xtrain]\n",
    "    XvalCorpus = [x for x in Xval]\n",
    "    vectorizer = CountVectorizer()\n",
    "    Xtrain = vectorizer.fit_transform(XtrainCorpus)\n",
    "    print('-'*15)\n",
    "    print(f\"Xtrain vectorized shape: {Xtrain.shape}\\n\")\n",
    "    Xval = vectorizer.transform(XvalCorpus)\n",
    "    print(f\"Xval vectorized shape: {Xval.shape}\\n\")\n",
    "    return (Xtrain,Xval)\n",
    "\n",
    "def Binarize(Ytrain,Yval):\n",
    "    \"\"\"  binarize The tags for Y train and validation sets. \"\"\"\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([Ytrain]) # if Y is not list of list, mlb.fit(['sci-fi', 'thriller', 'comedy']) -> array(['-', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'o', 'r', 's', 't','y'], dtype=object)\n",
    "    for i in Ytrain.index:\n",
    "        Ytrain.loc[i] = mlb.transform([[Ytrain.loc[i]]])[0]\n",
    "    for i in Yval.index:\n",
    "        Yval.loc[i] = mlb.transform([[Yval.loc[i]]])[0]\n",
    "    labels = mlb.classes_\n",
    "    print('-'*15)\n",
    "    print(f\"Ytrain vectorized shape: {Ytrain.shape}\\n\")\n",
    "    print(f\"Yval vectorized shape: {Yval.shape}\\n\")\n",
    "    print(f\"classes : {mlb.classes_}\")\n",
    "    return (Ytrain,Yval, labels)\n",
    "\n",
    "def plotRoc():\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(labels)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_val[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr[2],\n",
    "        tpr[2],\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "        label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
    "    )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clfScore(model,Xval, Yval, labels, fileName,PATH=path_res):                           #  correct position of the labels ???\n",
    "    y_pred = model.predict(Xval)\n",
    "    F1score=met.f1_score(y_pred, Yval, average=None)\n",
    "    preciScore=met.precision_score(y_pred, Yval, average=None)\n",
    "    recallScore=met.recall_score(y_pred, Yval, average=None)\n",
    "    print(f'{\"Tags\":25}\\t\\t F-score\\t\\t precision\\t\\t recall\\n')\n",
    "    with open(PATH + fileName,'w') as f:\n",
    "        for ind,name in enumerate(labels):\n",
    "            f.write(f'{name:25}\\t\\t {F1score[ind]:4f}\\t\\t {preciScore[ind]:4f}\\t\\t {recallScore[ind]:4f}\\n')\n",
    "            print(f'{name:25}\\t\\t {F1score[ind]:4f}\\t\\t {preciScore[ind]:4f}\\t\\t {recallScore[ind]:4f}')\n",
    "    #plotRoc(labels,y_pred,y_val)\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f9f98-233f-47bb-96f6-6e0da2643e06",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1ce52d0-0a06-478f-998d-4ead58194360",
   "metadata": {},
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c3257f-0006-4caf-b89c-f22362cc10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de préparation des sentences\n",
    "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
    "    input_ids=[]\n",
    "    token_type_ids = []\n",
    "    attention_mask=[]\n",
    "    bert_inp_tot = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens = True,\n",
    "                                              max_length = max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask = True, \n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "    \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
    "                             bert_inp['token_type_ids'][0], \n",
    "                             bert_inp['attention_mask'][0]))\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot\n",
    "    \n",
    "\n",
    "# Fonction de création des features\n",
    "def feature_BERT_fct(model, model_type, sentences, max_length, b_size, mode='HF') :\n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx+batch_size], \n",
    "                                                                      bert_tokenizer, max_length)\n",
    "        \n",
    "        if mode=='HF' :    # Bert HuggingFace\n",
    "            outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        if mode=='TFhub' : # Bert Tensorflow Hub\n",
    "            text_preprocessed = {\"input_word_ids\" : input_ids, \n",
    "                                 \"input_mask\" : attention_mask, \n",
    "                                 \"input_type_ids\" : token_type_ids}\n",
    "            outputs = model(text_preprocessed)\n",
    "            last_hidden_states = outputs['sequence_output']\n",
    "             \n",
    "        if step ==0 :\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "            last_hidden_states_tot_0 = last_hidden_states\n",
    "        else :\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot,last_hidden_states))\n",
    "    \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    \n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"temps traitement : \", time2)\n",
    "     \n",
    "    return features_bert, last_hidden_states_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2735b562-2a31-4fb9-b119-94962e4b8e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3' # https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n",
    "encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4' #https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
    "#tf.keras.backend.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15865e42-0c8c-468c-88d9-9cb7f354ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data used shape: (25952, 20)\n",
      "X_train types:\t<class 'pandas.core.series.Series'>\n",
      "X_test types:\t<class 'pandas.core.series.Series'>\n",
      "Y_test types:\t<class 'pandas.core.series.Series'>\n",
      "Y_train types:\t<class 'pandas.core.series.Series'>\n",
      "y_train shape: (17387,)\n",
      "\n",
      "y_val shape: (8565,)\n",
      "\n",
      "X_train shape: (17387,)\n",
      "\n",
      "X_val shape: (8565,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = splitData(data,XCol='tokens_WSW',Ycol='filtered_tags_reduced',ratioToKeep=0.5) # too much time without sampling\n",
    "print(f\"y_train shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val shape: {y_val.shape}\\n\")\n",
    "print(f\"X_train shape: {X_train.shape}\\n\")\n",
    "print(f\"X_val shape: {X_val.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4bc050e-220a-4938-b350-4c90dc7e79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: ' '.join(x).strip())\n",
    "X_val = X_val.apply(lambda x: ' '.join(x).strip())\n",
    "X_val.reset_index(inplace=True,drop=True)\n",
    "X_train.reset_index(inplace=True,drop=True)\n",
    "y_train.reset_index(inplace=True,drop=True)\n",
    "y_val.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e2fe6d-303c-4b44-9483-19ae44960ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        may right approach want conditionally add obje...\n",
       "1        trying dynamically generate classes python won...\n",
       "2        unary plus operator several definitions found ...\n",
       "3        hava app receive msg server make dialog user p...\n",
       "4        playing authlogic example app failing get emai...\n",
       "                               ...                        \n",
       "17382    installing liquidprompt documentation ask add ...\n",
       "17383    reading docs mobile changepage deprecated say ...\n",
       "17384    got backup application connects various webser...\n",
       "17385    php thread safe linux unix would possible use ...\n",
       "17386    currently process writing first windows forms ...\n",
       "Name: tokens_WSW, Length: 17387, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1bd4875-fc6a-4616-8a86-a0be73c66d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "bertPreprocess = hub.KerasLayer(preprocess_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d72566dc-8131-4ae8-a7ab-325907130526",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertModel = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55918e9e-7fe0-4547-a8cc-0c335dc128a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start X_train embeding\n",
      "start X_val embeding\n"
     ]
    }
   ],
   "source": [
    "batchSize = 100\n",
    "trainLen = len(X_train)\n",
    "valLen = len(X_val)\n",
    "\n",
    "print(\"start X_train embeding\")\n",
    "divisor = trainLen//batchSize\n",
    "remainder = trainLen%batchSize\n",
    "for i in range(divisor):\n",
    "    idx = batchSize*i\n",
    "    batch = X_train[idx:idx+batchSize]\n",
    "    batchPrepro = bertPreprocess(batch)\n",
    "    batchEmbedding = bertModel(batchPrepro)['pooled_output']\n",
    "    if i ==0:\n",
    "        resTrain = np.array(batchEmbedding)\n",
    "    else:\n",
    "        batchEmbedding = np.array(batchEmbedding)\n",
    "        resTrain = np.concatenate((resTrain,batchEmbedding))\n",
    "    if (i+1)==divisor and remainder !=0:\n",
    "        batch = X_train[divisor*batchSize:]\n",
    "        batchPrepro = bertPreprocess(batch)\n",
    "        batchEmbedding = bertModel(batchPrepro)['pooled_output']\n",
    "        batchEmbedding = np.array(batchEmbedding)\n",
    "        resTrain = np.concatenate((resTrain,batchEmbedding))  \n",
    "\n",
    "\n",
    "print(\"start X_val embeding\")\n",
    "divisor = valLen//batchSize\n",
    "remainder = valLen%batchSize\n",
    "for i in range(divisor):\n",
    "    idx = batchSize*i\n",
    "    batch = X_val[idx:idx+batchSize]\n",
    "    batchPrepro = bertPreprocess(batch)\n",
    "    batchEmbedding = bertModel(batchPrepro)['pooled_output']\n",
    "    if i ==0:\n",
    "        resVal = np.array(batchEmbedding)\n",
    "    else:\n",
    "        batchEmbedding = np.array(batchEmbedding)\n",
    "        resVal = np.concatenate((resVal,batchEmbedding))\n",
    "    if (i+1)==divisor and remainder !=0:\n",
    "        batch = X_val[divisor*batchSize:]\n",
    "        batchPrepro = bertPreprocess(batch)\n",
    "        batchEmbedding = bertModel(batchPrepro)['pooled_output']\n",
    "        batchEmbedding = np.array(batchEmbedding)\n",
    "        resVal = np.concatenate((resVal,batchEmbedding))  \n",
    "\n",
    "        \n",
    "X_train = resTrain\n",
    "X_val = resVal\n",
    "#X_trainPrepro = bertPreprocess(['i love banana','elon musk sucks','cars is bad for environment'])\n",
    "#X_valPrepro = bertPreprocess(['dungeons crawler are boring','i like pizza'])\n",
    "#X_trainEmbeding = bertModel(X_trainPrepro)\n",
    "#X_valEmbeding = bertModel(X_valPrepro)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07067a4b-fca4-4816-9401-7dc09ba04ce5",
   "metadata": {},
   "source": [
    "X_train = X_trainEmbeding['pooled_output']\n",
    "X_val = X_valEmbeding['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b137a7f2-fcab-46fc-8fa1-f6dfa2ef34fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tag25\n",
       "1     tag0\n",
       "2     tag9\n",
       "3     tag5\n",
       "4    tag21\n",
       "Name: filtered_tags_reduced, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a0be133-afe4-42b9-8e5b-ce5e9e04b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Ytrain vectorized shape: (17387,)\n",
      "\n",
      "Yval vectorized shape: (8565,)\n",
      "\n",
      "classes : ['tag0' 'tag1' 'tag10' 'tag108' 'tag11' 'tag12' 'tag13' 'tag14' 'tag15'\n",
      " 'tag16' 'tag17' 'tag18' 'tag19' 'tag2' 'tag20' 'tag21' 'tag22' 'tag23'\n",
      " 'tag24' 'tag25' 'tag26' 'tag27' 'tag28' 'tag29' 'tag3' 'tag30' 'tag31'\n",
      " 'tag32' 'tag33' 'tag34' 'tag35' 'tag36' 'tag37' 'tag38' 'tag4' 'tag5'\n",
      " 'tag6' 'tag7' 'tag8' 'tag9']\n",
      "y_train vectorized shape: (17387, 40)\n",
      "\n",
      "y_val vectorized shape: (8565, 40)\n",
      "\n",
      "---- After SMOTE ----\n",
      "y_train vectorized shape: (71680, 40)\n",
      "\n",
      "X_train vectorized shape: (71680, 768)\n",
      "\n",
      "---- Reduce size training set ----\n",
      "y_train vectorized shape: (17920, 40)\n",
      "\n",
      "y_val vectorized shape: (8565, 40)\n",
      "\n",
      "X_train vectorized shape: (17920, 768)\n",
      "\n",
      "X_val vectorized shape: (8565, 768)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_train = ['nice','bad','nice']\n",
    "#y_val = ['nice','bad']\n",
    "\n",
    "y_train, y_val, labels = Binarize(y_train,y_val)\n",
    "y_train = [ i for i in y_train]\n",
    "y_val = [ i for i in y_val]\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val vectorized shape: {y_val.shape}\\n\")\n",
    "\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train) # SMOTE\n",
    "X_train, y_train = shuffle(X_train,y_train, random_state=1)\n",
    "print(f\"---- After SMOTE ----\")\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"X_train vectorized shape: {X_train.shape}\\n\")\n",
    "\n",
    "print(f\"---- Reduce size training set ----\")\n",
    "X_train, y_train = reduceData(X_train ,y_train,ratioToKeep=0.25) #0.05\n",
    "\n",
    "print(f\"y_train vectorized shape: {y_train.shape}\\n\")\n",
    "print(f\"y_val vectorized shape: {y_val.shape}\\n\")\n",
    "print(f\"X_train vectorized shape: {X_train.shape}\\n\")\n",
    "print(f\"X_val vectorized shape: {X_val.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d1be93-1bfb-48f0-8580-f3a5c5332f7a",
   "metadata": {},
   "source": [
    "###  logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bf1c772-5e42-487f-9428-8858258b8038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "{'estimator__estimator__C': 10}\n"
     ]
    }
   ],
   "source": [
    "#y_train, y_val, labels = Binarize(y_train,y_val)\n",
    "\n",
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=0,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0))\n",
    "\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler()),('estimator',log_clf)])\n",
    "#raise Exception(\"trop long\") \n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__estimator__C': [0.1, 0.5, 1., 5, 10]}] # lambda regularization\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(model,\n",
    "                   param_grid,\n",
    "                   scoring='f1_macro', #F1 = 2 * (precision * recall) / (precision + recall)\n",
    "                   n_jobs=-1,\n",
    "                   verbose=0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "log_clf_best_param = clf.best_params_['estimator__estimator__C']\n",
    "print('Meilleurs hyper-paramètres :')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df509ef8-dbfe-4f93-b026-7c29147a5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags                     \t\t F-score\t\t precision\t\t recall\n",
      "\n",
      "tag0                     \t\t 0.309579\t\t 0.238489\t\t 0.441048\n",
      "tag1                     \t\t 0.165829\t\t 0.114983\t\t 0.297297\n",
      "tag10                    \t\t 0.310139\t\t 0.380488\t\t 0.261745\n",
      "tag108                   \t\t 0.336192\t\t 0.374046\t\t 0.305296\n",
      "tag11                    \t\t 0.169492\t\t 0.218447\t\t 0.138462\n",
      "tag12                    \t\t 0.603675\t\t 0.628415\t\t 0.580808\n",
      "tag13                    \t\t 0.127473\t\t 0.166667\t\t 0.103203\n",
      "tag14                    \t\t 0.288557\t\t 0.351515\t\t 0.244726\n",
      "tag15                    \t\t 0.169903\t\t 0.239726\t\t 0.131579\n",
      "tag16                    \t\t 0.122807\t\t 0.193103\t\t 0.090032\n",
      "tag17                    \t\t 0.185615\t\t 0.285714\t\t 0.137457\n",
      "tag18                    \t\t 0.173697\t\t 0.294118\t\t 0.123239\n",
      "tag19                    \t\t 0.375796\t\t 0.483607\t\t 0.307292\n",
      "tag2                     \t\t 0.293240\t\t 0.241679\t\t 0.372768\n",
      "tag20                    \t\t 0.170543\t\t 0.286957\t\t 0.121324\n",
      "tag21                    \t\t 0.189944\t\t 0.293103\t\t 0.140496\n",
      "tag22                    \t\t 0.117264\t\t 0.156522\t\t 0.093750\n",
      "tag23                    \t\t 0.190202\t\t 0.289474\t\t 0.141631\n",
      "tag24                    \t\t 0.070845\t\t 0.173333\t\t 0.044521\n",
      "tag25                    \t\t 0.207283\t\t 0.342593\t\t 0.148594\n",
      "tag26                    \t\t 0.198718\t\t 0.313131\t\t 0.145540\n",
      "tag27                    \t\t 0.085960\t\t 0.154639\t\t 0.059524\n",
      "tag28                    \t\t 0.270833\t\t 0.419355\t\t 0.200000\n",
      "tag29                    \t\t 0.308333\t\t 0.552239\t\t 0.213873\n",
      "tag3                     \t\t 0.249783\t\t 0.185567\t\t 0.381963\n",
      "tag30                    \t\t 0.191304\t\t 0.289474\t\t 0.142857\n",
      "tag31                    \t\t 0.180258\t\t 0.300000\t\t 0.128834\n",
      "tag32                    \t\t 0.179104\t\t 0.257143\t\t 0.137405\n",
      "tag33                    \t\t 0.188525\t\t 0.323944\t\t 0.132948\n",
      "tag34                    \t\t 0.146939\t\t 0.285714\t\t 0.098901\n",
      "tag35                    \t\t 0.420000\t\t 0.552632\t\t 0.338710\n",
      "tag36                    \t\t 0.054545\t\t 0.089552\t\t 0.039216\n",
      "tag37                    \t\t 0.145251\t\t 0.183099\t\t 0.120370\n",
      "tag38                    \t\t 0.256410\t\t 0.403226\t\t 0.187970\n",
      "tag4                     \t\t 0.259394\t\t 0.251174\t\t 0.268170\n",
      "tag5                     \t\t 0.442916\t\t 0.443526\t\t 0.442308\n",
      "tag6                     \t\t 0.285714\t\t 0.297030\t\t 0.275229\n",
      "tag7                     \t\t 0.220126\t\t 0.270270\t\t 0.185676\n",
      "tag8                     \t\t 0.241431\t\t 0.252336\t\t 0.231429\n",
      "tag9                     \t\t 0.186567\t\t 0.221239\t\t 0.161290\n"
     ]
    }
   ],
   "source": [
    "log_clf = OneVsRestClassifier(LogisticRegression(random_state=42,\n",
    "                                                 max_iter=10000,\n",
    "                                                 verbose=0,\n",
    "                                                C=log_clf_best_param))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler()),('estimator',log_clf)])\n",
    "model.fit(X_train, y_train)\n",
    "clfScore(model, X_val,y_val, labels,'bert_logistic_reduced_without_empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8a835-b7ae-419f-aa81-a399d508840e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ded79e8-2b7a-4c2d-96e8-3df67f029cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyper-paramètres :\n",
      "{'estimator__estimator__max_depth': 15, 'estimator__estimator__n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "RF_clf = OneVsRestClassifier(RF(min_samples_split=5))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler(with_mean=False)),('estimator',RF_clf)])\n",
    "#raise Exception(\"trop long\") \n",
    "# hyperparameters\n",
    "param_grid = [{'estimator__estimator__n_estimators': [10,20,30],'estimator__estimator__max_depth' : [5,8,10,15]}]\n",
    "\n",
    "# cross-validation\n",
    "clf = GridSearchCV(model,\n",
    "                   param_grid,\n",
    "                   scoring='f1_macro', #F1 = 2 * (precision * recall) / (precision + recall)\n",
    "                   n_jobs=-1,\n",
    "                   verbose=0,\n",
    "                   cv=5,\n",
    "                   return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "RF_clf_best_param1 = clf.best_params_['estimator__estimator__n_estimators']\n",
    "RF_clf_best_param2 = clf.best_params_['estimator__estimator__max_depth']\n",
    "print('Meilleurs hyper-paramètres :')\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aed0c023-7555-4c61-ab48-31f3be0eaa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags                     \t\t F-score\t\t precision\t\t recall\n",
      "\n",
      "tag0                     \t\t 0.009270\t\t 0.004723\t\t 0.250000\n",
      "tag1                     \t\t 0.004582\t\t 0.002323\t\t 0.166667\n",
      "tag10                    \t\t 0.025424\t\t 0.014634\t\t 0.096774\n",
      "tag108                   \t\t 0.007194\t\t 0.003817\t\t 0.062500\n",
      "tag11                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag12                    \t\t 0.010050\t\t 0.005464\t\t 0.062500\n",
      "tag13                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag14                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag15                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag16                    \t\t 0.013072\t\t 0.006897\t\t 0.125000\n",
      "tag17                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag18                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag19                    \t\t 0.072464\t\t 0.040984\t\t 0.312500\n",
      "tag2                     \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag20                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag21                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag22                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag23                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag24                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag25                    \t\t 0.016393\t\t 0.009259\t\t 0.071429\n",
      "tag26                    \t\t 0.060606\t\t 0.040404\t\t 0.121212\n",
      "tag27                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag28                    \t\t 0.038095\t\t 0.021505\t\t 0.166667\n",
      "tag29                    \t\t 0.023529\t\t 0.014925\t\t 0.055556\n",
      "tag3                     \t\t 0.007557\t\t 0.003866\t\t 0.166667\n",
      "tag30                    \t\t 0.021505\t\t 0.013158\t\t 0.058824\n",
      "tag31                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag32                    \t\t 0.025000\t\t 0.014286\t\t 0.100000\n",
      "tag33                    \t\t 0.024096\t\t 0.014085\t\t 0.083333\n",
      "tag34                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag35                    \t\t 0.021505\t\t 0.013158\t\t 0.058824\n",
      "tag36                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag37                    \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag38                    \t\t 0.027778\t\t 0.016129\t\t 0.100000\n",
      "tag4                     \t\t 0.004515\t\t 0.002347\t\t 0.058824\n",
      "tag5                     \t\t 0.070886\t\t 0.038567\t\t 0.437500\n",
      "tag6                     \t\t 0.000000\t\t 0.000000\t\t 0.000000\n",
      "tag7                     \t\t 0.007220\t\t 0.003861\t\t 0.055556\n",
      "tag8                     \t\t 0.012085\t\t 0.006231\t\t 0.200000\n",
      "tag9                     \t\t 0.016064\t\t 0.008850\t\t 0.086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DevPackages\\lib\\site-packages\\joblib\\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\\Users\\thomas\\AppData\\Local\\Temp\\joblib_memmapping_folder_8908_13111fc20bfc4197af16402b01cd72be_6054be3b75a046e4a4be3a906b424548\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "D:\\DevPackages\\lib\\site-packages\\joblib\\_memmapping_reducer.py:611: UserWarning: Failed to delete temporary folder: C:\\Users\\thomas\\AppData\\Local\\Temp\\joblib_memmapping_folder_8908_140630013dab400a9d805cb44094c53a_41b67a2ab09749e1adf82cf1d6aa79f6\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n"
     ]
    }
   ],
   "source": [
    "RF_clf = OneVsRestClassifier(RF(n_estimators=RF_clf_best_param1,\n",
    "                                                  max_depth=RF_clf_best_param2,\n",
    "                                                   min_samples_split=5))\n",
    "model = Pipeline(steps=[(\"scaler\" , StandardScaler(with_mean=False)),('estimator',RF_clf)])\n",
    "model.fit(X_train, y_train)\n",
    "clfScore(model, X_val,y_val, labels,'bert_RF_reduced_without_empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211efa66-c148-4e61-8055-a307875894f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12000 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
